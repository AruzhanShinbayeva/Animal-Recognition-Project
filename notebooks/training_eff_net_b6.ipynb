{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9730298,"sourceType":"datasetVersion","datasetId":5954512}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\nimport json\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nfrom datasets import load_dataset\n\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, IterableDataset\n\n# from torchvision import transforms\nfrom sklearn.metrics import accuracy_score\n\nfrom typing import Any, Tuple, List\n\nfrom cv2 import Mat\nfrom numpy import dtype, floating, integer, ndarray\n\nfrom tqdm.autonotebook import tqdm\n\nplt.rcParams[\"figure.figsize\"] = (16, 10)  # (w, h)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:02:41.631694Z","iopub.execute_input":"2024-10-26T20:02:41.632675Z","iopub.status.idle":"2024-10-26T20:02:48.445312Z","shell.execute_reply.started":"2024-10-26T20:02:41.632607Z","shell.execute_reply":"2024-10-26T20:02:48.444299Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/input/annototion-iwildcam2020/iwildcam2020_train_annotations.json\") as f:\n    data = json.load(f)\n\n\nannotations = pd.DataFrame.from_dict(data[\"annotations\"])\nimages_metadata = pd.DataFrame.from_dict(data[\"images\"])\ncategories = pd.DataFrame.from_dict(data[\"categories\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:02:48.447649Z","iopub.execute_input":"2024-10-26T20:02:48.448290Z","iopub.status.idle":"2024-10-26T20:02:51.463191Z","shell.execute_reply.started":"2024-10-26T20:02:48.448240Z","shell.execute_reply":"2024-10-26T20:02:51.462090Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# convert datetime type and split into day/night time\ndef split_day_night_time(\n    data: pd.DataFrame, day_start: str = \"06:00:00\", day_end: str = \"18:00:00\"\n) -> pd.DataFrame:\n    data = data.copy()\n    data[\"datetime\"] = pd.to_datetime(data[\"datetime\"])\n    data[\"is_day\"] = data[\"datetime\"].apply(\n        lambda x: True\n        if pd.Timestamp(day_start).time() <= x.time() < pd.Timestamp(day_end).time()\n        else False\n    )\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:02:51.464441Z","iopub.execute_input":"2024-10-26T20:02:51.464772Z","iopub.status.idle":"2024-10-26T20:02:51.471045Z","shell.execute_reply.started":"2024-10-26T20:02:51.464738Z","shell.execute_reply":"2024-10-26T20:02:51.470040Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def preprocess_dark_images(\n    image: np.ndarray,\n) -> Mat | ndarray[Any, dtype[integer[Any] | floating[Any]]]:\n    img = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n    img_eq = img.copy()\n    img_eq[:, :, 0] = cv2.equalizeHist(img[:, :, 0])\n    final_img = cv2.cvtColor(img_eq, cv2.COLOR_LUV2RGB)\n    return final_img","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:02:51.472313Z","iopub.execute_input":"2024-10-26T20:02:51.473185Z","iopub.status.idle":"2024-10-26T20:02:51.483156Z","shell.execute_reply.started":"2024-10-26T20:02:51.473153Z","shell.execute_reply":"2024-10-26T20:02:51.482330Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\n\nclass iWildCam2020Dataset(IterableDataset):\n    def __init__(\n        self,\n        dataset: str,\n        metadata: pd.DataFrame,\n        batch_size: int = 16,\n        resize_dim: Tuple[int, int] | None = None,\n        num_samples: int = 1000,\n        mean: np.ndarray | None = None,\n        std: np.ndarray | None = None,\n        save_dir: str | None = None,\n        overwrite: bool = False,\n        split: str = \"train\",\n        val_ratio: float = 0.2,\n    ):\n        super().__init__()\n        self.metadata = metadata\n\n        self.split = split\n        self.val_ratio = val_ratio\n        self.train_size = int((1 - val_ratio) * num_samples)\n        self.val_size = num_samples - self.train_size\n\n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.resize_dim = resize_dim\n\n        self.num_samples = num_samples\n        if self.split == \"train\":\n            self.num_batches = (self.train_size + batch_size - 1) // batch_size\n        else:\n            self.num_batches= (self.val_size + batch_size - 1) // batch_size\n\n        self.mean = torch.tensor(mean if mean is not None else [0.0, 0.0, 0.0]).view(\n            3, 1, 1\n        )\n        self.std = torch.tensor(std if std is not None else [1.0, 1.0, 1.0]).view(\n            3, 1, 1\n        )\n\n        self.save_dir = Path(save_dir) if save_dir else None\n        if self.save_dir:\n            self.save_dir.mkdir(parents=True, exist_ok=True)\n        self.overwrite = overwrite\n\n    def save_image(self, img_tensor: torch.Tensor, idx: int):\n        if self.save_dir:\n            save_path = self.save_dir / f\"image_{idx}.pt\"\n            torch.save(img_tensor, save_path)\n    \n    def load_image(self, idx: int) -> torch.Tensor | None:\n        if self.save_dir:\n            save_path = self.save_dir / f\"image_{idx}.pt\"\n            if save_path.exists():\n                return torch.load(save_path, weights_only=True)\n        return None\n    \n    def __len__(self):\n        return self.num_batches\n\n    def __iter__(self):\n        if self.split == \"train\":\n            start_idx, end_idx = 0, self.train_size\n        else:\n            start_idx, end_idx = self.train_size, self.num_samples\n        \n        for idx, image_batch in enumerate(self.dataset.iter(self.batch_size)):\n            # to get consistent part of dataset + val / train split\n            batch_start = idx * self.batch_size\n            if batch_start >= end_idx:\n                break\n            if batch_start < start_idx:\n                continue\n            \n            is_day = self.metadata[idx * self.batch_size : (idx + 1) * self.batch_size][\n                \"is_day\"\n            ].values\n            image_batch = image_batch[\"image\"]\n            imgs_ = []\n\n            dark_idx = set(np.where(~is_day)[0].tolist())\n            for i in range(len(image_batch)):\n                img_tensor = self.load_image(idx * self.batch_size + i)\n                if img_tensor is None:\n                    img = np.transpose(image_batch[i].numpy())\n                    if i in dark_idx:\n                        img = preprocess_dark_images(img)\n                    img = cv2.resize(img, self.resize_dim, interpolation=cv2.INTER_AREA)\n                    img_tensor = (\n                        torch.tensor(np.transpose(img, (2, 0, 1)), dtype=torch.float32)\n                        / 255.0\n                    )\n\n                    if self.save_dir:\n                        self.save_image(img_tensor, idx * self.batch_size + i)\n\n                imgs_.append(img_tensor)\n            yield torch.stack(imgs_)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:02:51.486037Z","iopub.execute_input":"2024-10-26T20:02:51.486324Z","iopub.status.idle":"2024-10-26T20:02:51.507189Z","shell.execute_reply.started":"2024-10-26T20:02:51.486295Z","shell.execute_reply":"2024-10-26T20:02:51.506240Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def calculate_mean_std(dataset, batch_size=32, resize_dim=(224, 224), num_samples=1000):\n    means = []\n    stds = []\n    for idx, image_batch in tqdm(enumerate(dataset.iter(batch_size)), total = ((num_samples + batch_size - 1) // batch_size)):\n        if idx * batch_size >= num_samples:\n            break\n\n        imgs_ = []\n        for image in image_batch[\"image\"]:\n            img = np.transpose(image.numpy(), (1, 2, 0))\n            img = cv2.resize(img, resize_dim, interpolation=cv2.INTER_AREA)\n            img = img / 255.0\n            imgs_.append(img)\n\n        imgs_array = np.stack(imgs_)\n        means.append(imgs_array.mean(axis=(0, 1, 2)))\n        stds.append(imgs_array.std(axis=(0, 1, 2)))\n\n    mean = np.mean(means, axis=0)\n    std = np.mean(stds, axis=0)\n    return mean, std","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:02:51.508226Z","iopub.execute_input":"2024-10-26T20:02:51.508525Z","iopub.status.idle":"2024-10-26T20:02:51.521448Z","shell.execute_reply.started":"2024-10-26T20:02:51.508495Z","shell.execute_reply":"2024-10-26T20:02:51.520749Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def train(\n    model,\n    criterion,\n    optimizer,\n    train_loader,\n    val_loader,\n    batch_size,\n    device,\n    num_epochs=1,\n    ckpt_path=\"best.pt\"\n):\n    best = 0.0\n    for epoch in range(num_epochs):\n        train_loop = tqdm(\n            enumerate(train_loader, 0),\n            total=len(train_loader),\n            desc=f\"Epoch {epoch}: train\",\n        )\n\n        model.train()\n        train_loss = 0.0\n\n        for i, batch in train_loop:\n            images = batch.to(device)\n            labels = torch.tensor(\n                annotations[\"category_id\"][\n                    epoch * (len(train_loader) * batch_size) + batch_size * i : min(\n                        epoch * (len(train_loader) * batch_size) + batch_size * (i + 1),\n                        len(annotations[\"category_id\"]),\n                    )\n                ].values\n            ).to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            train_loop.set_postfix({\"loss\": loss.item()})\n\n        correct = 0\n        total = 0\n        val_loss = 0\n        with torch.no_grad():\n            model.eval()\n\n            val_loop = tqdm(\n                enumerate(val_loader, 0),\n                total=len(val_loader),\n                desc=f\"Val\",\n            )\n\n            for i, batch in val_loop:\n                images = batch.to(device)\n                labels = torch.tensor(\n                    annotations[\"category_id\"][\n                        epoch * len(train_loader) * batch_size\n                        + batch_size * i : min(\n                            epoch * len(train_loader) * batch_size\n                            + batch_size * (i + 1),\n                            len(annotations[\"category_id\"]),\n                        )\n                    ].values\n                ).to(device)\n\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n                val_loop.set_postfix({\"acc\": correct / total, \"loss\": val_loss / (i + 1)})\n\n\n            val_accuracy = correct / total\n            \n            print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_loss / len(train_loader):.6f}\")\n            print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {val_accuracy:.6f}, Validation Loss: {val_loss:.6f}\")\n            \n            if val_accuracy > best:\n                torch.save(model.state_dict(), ckpt_path)\n                best = correct / total","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:02:51.522626Z","iopub.execute_input":"2024-10-26T20:02:51.522990Z","iopub.status.idle":"2024-10-26T20:02:51.538479Z","shell.execute_reply.started":"2024-10-26T20:02:51.522949Z","shell.execute_reply":"2024-10-26T20:02:51.537618Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\n    \"anngrosha/iWildCam2020\", split=\"train\", streaming=True\n).with_format(\"torch\")","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:02:51.539529Z","iopub.execute_input":"2024-10-26T20:02:51.539888Z","iopub.status.idle":"2024-10-26T20:02:54.036238Z","shell.execute_reply.started":"2024-10-26T20:02:51.539856Z","shell.execute_reply":"2024-10-26T20:02:54.035426Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/406 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"251f1a60e3564ee7804e333b2e4c0c07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/190 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211624fae8214225b73c944264d084ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/52 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70610ce463084ab69cf3bdec214f2c52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/190 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2fd8015a9de437bb1e70261e31832e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/52 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab2b60b98d214f7fbc23402c9eefe03a"}},"metadata":{}}]},{"cell_type":"code","source":"images_metadata = split_day_night_time(images_metadata)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:02:54.037333Z","iopub.execute_input":"2024-10-26T20:02:54.037655Z","iopub.status.idle":"2024-10-26T20:03:12.673413Z","shell.execute_reply.started":"2024-10-26T20:02:54.037622Z","shell.execute_reply":"2024-10-26T20:03:12.672621Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"batch_size = 5\nimg_size = 528\nresize_dim = (img_size, img_size)\nnum_classes = max(annotations[\"category_id\"])\n\nnum_samples = 5\nval_ratio = 0\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:21:23.236273Z","iopub.execute_input":"2024-10-26T20:21:23.236692Z","iopub.status.idle":"2024-10-26T20:21:23.270432Z","shell.execute_reply.started":"2024-10-26T20:21:23.236653Z","shell.execute_reply":"2024-10-26T20:21:23.269166Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"[EfficientNet b6](https://arxiv.org/pdf/1905.11946)","metadata":{}},{"cell_type":"code","source":"from torchvision import models\n\n# Taking model and weights from torch\nmodel_name = \"efficientnet_b6\"\nmodel = getattr(models, model_name)(weights=\"IMAGENET1K_V1\").to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:24:23.918968Z","iopub.execute_input":"2024-10-26T20:24:23.919342Z","iopub.status.idle":"2024-10-26T20:24:24.837469Z","shell.execute_reply.started":"2024-10-26T20:24:23.919307Z","shell.execute_reply":"2024-10-26T20:24:24.836626Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"mean, std = calculate_mean_std(\n    dataset, batch_size=batch_size, resize_dim=resize_dim, num_samples=num_samples\n)\nmean, std","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:21:26.783840Z","iopub.execute_input":"2024-10-26T20:21:26.784221Z","iopub.status.idle":"2024-10-26T20:21:28.772839Z","shell.execute_reply.started":"2024-10-26T20:21:26.784184Z","shell.execute_reply":"2024-10-26T20:21:28.771846Z"},"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ec27e0009c44087b91950633a9e802c"}},"metadata":{}},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"(array([0.28920419, 0.30016643, 0.27284901]),\n array([0.25199852, 0.2551511 , 0.26412713]))"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = iWildCam2020Dataset(\n    dataset=dataset,\n    metadata=images_metadata,\n    batch_size=batch_size,\n    resize_dim=resize_dim,\n    num_samples=num_samples,\n    mean=mean,\n    std=std,\n    save_dir=\"/working/data/train\",\n    split=\"train\",\n    val_ratio=val_ratio\n)\n\nval_dataset = iWildCam2020Dataset(\n    dataset=dataset,\n    metadata=images_metadata,\n    batch_size=batch_size,\n    resize_dim=resize_dim,\n    num_samples=num_samples,\n    mean=mean,\n    std=std,\n    save_dir=\"/working/data/val\",\n    split=\"val\",\n    val_ratio=val_ratio\n)\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=None)\nval_loader = DataLoader(val_dataset, batch_size=None)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:21:29.250321Z","iopub.execute_input":"2024-10-26T20:21:29.250845Z","iopub.status.idle":"2024-10-26T20:21:29.258764Z","shell.execute_reply.started":"2024-10-26T20:21:29.250803Z","shell.execute_reply":"2024-10-26T20:21:29.257691Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adadelta(model.parameters(), lr=1)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:24:25.524527Z","iopub.execute_input":"2024-10-26T20:24:25.525364Z","iopub.status.idle":"2024-10-26T20:24:25.533990Z","shell.execute_reply.started":"2024-10-26T20:24:25.525324Z","shell.execute_reply":"2024-10-26T20:24:25.532915Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# train(\n#     model,\n#     criterion,\n#     optimizer,\n#     batch_loader,\n#     #val_loader,\n#     batch_loader,\n#     batch_size,\n#     device,\n#     num_epochs=20\n# )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performing singe-batch overfitting to see if model capable enought for our task","metadata":{}},{"cell_type":"code","source":"batch_dataset = iWildCam2020Dataset(\n    dataset=dataset,\n    metadata=images_metadata,\n    batch_size=batch_size,\n    resize_dim=resize_dim,\n    num_samples=num_samples,\n    mean=mean,\n    std=std,\n    save_dir=\"/working/data/train\",\n    split=\"train\",\n    val_ratio=0\n)\nbatch_loader = DataLoader(batch_dataset, batch_size=None)\n\ntrain(\n    model,\n    criterion,\n    optimizer,\n    batch_loader,\n    batch_loader,\n    batch_size,\n    device,\n    num_epochs=20\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T20:24:27.063092Z","iopub.execute_input":"2024-10-26T20:24:27.064065Z","iopub.status.idle":"2024-10-26T20:25:51.940672Z","shell.execute_reply.started":"2024-10-26T20:24:27.064023Z","shell.execute_reply":"2024-10-26T20:25:51.939609Z"},"trusted":true},"execution_count":59,"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch 0: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe809aa613994cee99e1e19313127fa6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29b4d33d27894795894512f2863ea3d9"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/20], Training Loss: 7.174567\nEpoch [1/20], Validation Accuracy: 0.400000, Validation Loss: 4.951488\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7403d210a11b44c98703a315054c229d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06e6cc1c17d24213805c1d23729e2dfc"}},"metadata":{}},{"name":"stdout","text":"Epoch [2/20], Training Loss: 8.946634\nEpoch [2/20], Validation Accuracy: 0.000000, Validation Loss: 6.312703\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c7a25eb60b34cbab36bbd679561dee9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afa9af46c6e440cc9c82431f49d7f62a"}},"metadata":{}},{"name":"stdout","text":"Epoch [3/20], Training Loss: 8.863723\nEpoch [3/20], Validation Accuracy: 0.200000, Validation Loss: 4.501873\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7aa4c388e80f482987ef145f4c3eba43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b81e39335044af98a2fcf7e10a75b95"}},"metadata":{}},{"name":"stdout","text":"Epoch [4/20], Training Loss: 9.617105\nEpoch [4/20], Validation Accuracy: 0.000000, Validation Loss: 6.081414\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9875b8c6e2004b368a7aad33bcf015ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfc9539f538540cd9150289eb7bce629"}},"metadata":{}},{"name":"stdout","text":"Epoch [5/20], Training Loss: 6.618913\nEpoch [5/20], Validation Accuracy: 0.400000, Validation Loss: 4.637212\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb7d47172c1346eba6dd46bc62953111"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d8222b41bcc40488316d05b0f064dc3"}},"metadata":{}},{"name":"stdout","text":"Epoch [6/20], Training Loss: 7.105976\nEpoch [6/20], Validation Accuracy: 0.800000, Validation Loss: 1.638704\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4987e81c83374e08b55a830786d26361"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"491fabb739a04854ba8cedf2d11e12bd"}},"metadata":{}},{"name":"stdout","text":"Epoch [7/20], Training Loss: 4.482521\nEpoch [7/20], Validation Accuracy: 0.200000, Validation Loss: 3.526148\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc36c2e0084e4e3888cb95e9235e7b67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d1e447542bf47d68e709678b09b3356"}},"metadata":{}},{"name":"stdout","text":"Epoch [8/20], Training Loss: 7.732214\nEpoch [8/20], Validation Accuracy: 0.000000, Validation Loss: 4.774188\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c9c864f37884b009c54e858c8b23c2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baff366d848a4296b0590c7406b4227a"}},"metadata":{}},{"name":"stdout","text":"Epoch [9/20], Training Loss: 3.922909\nEpoch [9/20], Validation Accuracy: 0.600000, Validation Loss: 2.675139\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05b0cc9a685c42e4b900f82e6606690d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97ef59b52ebb4d9990fb760031961fe4"}},"metadata":{}},{"name":"stdout","text":"Epoch [10/20], Training Loss: 3.456730\nEpoch [10/20], Validation Accuracy: 0.600000, Validation Loss: 2.236564\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68e82ec7832e4f6bbf785c65cf2552b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de210cac2267439ab66dcfe41bf3fa44"}},"metadata":{}},{"name":"stdout","text":"Epoch [11/20], Training Loss: 2.569155\nEpoch [11/20], Validation Accuracy: 0.600000, Validation Loss: 2.626611\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 11: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ff24c3d5ac9424891a32539d4a6b170"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dfe8585658a47a2b359574d9d5299d3"}},"metadata":{}},{"name":"stdout","text":"Epoch [12/20], Training Loss: 6.069652\nEpoch [12/20], Validation Accuracy: 0.200000, Validation Loss: 5.293307\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 12: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe79468ce85f4d0da653cde687ded2b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4d6ea072f6d48189fe2249d07387fae"}},"metadata":{}},{"name":"stdout","text":"Epoch [13/20], Training Loss: 6.623686\nEpoch [13/20], Validation Accuracy: 0.200000, Validation Loss: 5.224122\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 13: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd63fddd16314f438742b4e876fe6dad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bf1a366b12044ddbd5bcc009581a037"}},"metadata":{}},{"name":"stdout","text":"Epoch [14/20], Training Loss: 4.714277\nEpoch [14/20], Validation Accuracy: 0.200000, Validation Loss: 4.555107\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 14: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"244f6d966c3f4bf68c9fd2d24bb998ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"633bf28fabe14f3a8ae23e3901052247"}},"metadata":{}},{"name":"stdout","text":"Epoch [15/20], Training Loss: 4.935735\nEpoch [15/20], Validation Accuracy: 0.400000, Validation Loss: 4.257748\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 15: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c2c4d0343be42388cac5889d905864b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ce6ddee9abe4303887e91b171d12f49"}},"metadata":{}},{"name":"stdout","text":"Epoch [16/20], Training Loss: 3.372406\nEpoch [16/20], Validation Accuracy: 0.200000, Validation Loss: 3.485958\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 16: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61ff0c1e9416412aa52f988b866d18ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d426e5b6acf24b55baace70308126b39"}},"metadata":{}},{"name":"stdout","text":"Epoch [17/20], Training Loss: 1.781539\nEpoch [17/20], Validation Accuracy: 0.600000, Validation Loss: 1.861057\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 17: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23d800f6ac9343c497c6cbbe7446c60b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c2d42a702994d04833fde3374cb6293"}},"metadata":{}},{"name":"stdout","text":"Epoch [18/20], Training Loss: 0.081399\nEpoch [18/20], Validation Accuracy: 0.600000, Validation Loss: 1.785450\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 18: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ada01779a73049239200c3fce1546f0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9cd2d7949224e7f9d90fd2acdafa25d"}},"metadata":{}},{"name":"stdout","text":"Epoch [19/20], Training Loss: 7.920228\nEpoch [19/20], Validation Accuracy: 0.200000, Validation Loss: 4.967960\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 19: train:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3619cdbba7a7424abaa3e9f9f131c162"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bfddcebe7254f6c8483f4dfc8e65aec"}},"metadata":{}},{"name":"stdout","text":"Epoch [20/20], Training Loss: 6.695241\nEpoch [20/20], Validation Accuracy: 0.000000, Validation Loss: 5.587543\n","output_type":"stream"}]}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "\n",
    "from typing import Any, Tuple, List\n",
    "\n",
    "from cv2 import Mat\n",
    "from numpy import dtype, floating, integer, ndarray\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 10)  # (w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/iwildcam2020_train_annotations.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "annotations = pd.DataFrame.from_dict(data[\"annotations\"])\n",
    "images_metadata = pd.DataFrame.from_dict(data[\"images\"])\n",
    "categories = pd.DataFrame.from_dict(data[\"categories\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 217959 entries, 0 to 217958\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   seq_num_frames  217959 non-null  int64 \n",
      " 1   location        217959 non-null  int64 \n",
      " 2   datetime        217959 non-null  object\n",
      " 3   id              217959 non-null  object\n",
      " 4   frame_num       217959 non-null  int64 \n",
      " 5   seq_id          217959 non-null  object\n",
      " 6   width           217959 non-null  int64 \n",
      " 7   height          217959 non-null  int64 \n",
      " 8   file_name       217959 non-null  object\n",
      "dtypes: int64(5), object(4)\n",
      "memory usage: 15.0+ MB\n"
     ]
    }
   ],
   "source": [
    "images_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datetime type and split into day/night time\n",
    "def split_day_night_time(\n",
    "    data: pd.DataFrame, day_start: str = \"06:00:00\", day_end: str = \"18:00:00\"\n",
    ") -> pd.DataFrame:\n",
    "    data = data.copy()\n",
    "    data[\"datetime\"] = pd.to_datetime(data[\"datetime\"])\n",
    "    data[\"is_day\"] = data[\"datetime\"].apply(\n",
    "        lambda x: True\n",
    "        if pd.Timestamp(day_start).time() <= x.time() < pd.Timestamp(day_end).time()\n",
    "        else False\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dark_images(\n",
    "    image: np.ndarray,\n",
    ") -> Mat | ndarray[Any, dtype[integer[Any] | floating[Any]]]:\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "    img_eq = img.copy()\n",
    "    img_eq[:, :, 0] = cv2.equalizeHist(img[:, :, 0])\n",
    "    final_img = cv2.cvtColor(img_eq, cv2.COLOR_LUV2RGB)\n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "class iWildCam2020Dataset(IterableDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: str,\n",
    "        metadata: pd.DataFrame,\n",
    "        batch_size: int = 16,\n",
    "        resize_dim: Tuple[int, int] | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.metadata = metadata\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.resize_dim = resize_dim\n",
    "\n",
    "    def __iter__(self):  # -> Generator[Any, Any, None]:\n",
    "        for idx, image_batch in enumerate(self.dataset.iter(self.batch_size)):\n",
    "            is_day = self.metadata[idx : idx + self.batch_size][\"is_day\"].values\n",
    "            image_batch = image_batch[\"image\"]\n",
    "\n",
    "            dark_idx = set(np.where(~is_day)[0].tolist())\n",
    "            for i in range(len(image_batch)):\n",
    "                img = np.transpose(image_batch[i].numpy())\n",
    "                print(img.shape)\n",
    "                if i in dark_idx:\n",
    "                    img = preprocess_dark_images(img)\n",
    "                img = np.array(Image.fromarray(img).resize(self.resize_dim))\n",
    "                #img = cv2.resize(img, self.resize_dim, interpolation=cv2.INTER_AREA)\n",
    "                print(img.shape, \"\\n\\n\\n\")\n",
    "                #torch error\n",
    "                image_batch[i] = torch.tensor(np.transpose(img))\n",
    "            yield image_batch\n",
    "\t\t\t#yield torch.stack(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_metadata = split_day_night_time(images_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace08692c9a7446e9b27418d667264cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab9e732c7d1427bb6ec94123f51d073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812bac0659694e54a11963f79d5b701c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7092f3410ec4d038f46b2597f0e9ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"anngrosha/iWildCam2020\", split=\"train\", streaming=True\n",
    ").with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2592, 1944, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1280, 1024, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1280, 1024, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1280, 1024, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1280, 1024, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1280, 1024, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1280, 1024, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1280, 1024, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1280, 1024, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1280, 1024, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2592, 1944, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1280, 1024, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1280, 1024, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1280, 1024, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(1920, 1080, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n",
      "(2048, 1536, 3)\n",
      "(1000, 1000, 3) \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (2048) must match the existing size (1000) at non-singleton dimension 2.  Target sizes: [3, 1536, 2048].  Tensor sizes: [3, 1000, 1000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset_iteratable \u001b[38;5;241m=\u001b[39m iWildCam2020Dataset(\n\u001b[1;32m      2\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m      3\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mimages_metadata,\n\u001b[1;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m      5\u001b[0m     resize_dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1000\u001b[39m),\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset_iteratable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#print(batch.shape)\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n",
      "Cell \u001b[0;32mIn[133], line 34\u001b[0m, in \u001b[0;36miWildCam2020Dataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#torch error\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     \u001b[43mimage_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mtranspose(img))\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m image_batch\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (2048) must match the existing size (1000) at non-singleton dimension 2.  Target sizes: [3, 1536, 2048].  Tensor sizes: [3, 1000, 1000]"
     ]
    }
   ],
   "source": [
    "dataset_iteratable = iWildCam2020Dataset(\n",
    "    dataset=dataset,\n",
    "    metadata=images_metadata,\n",
    "    batch_size=batch_size,\n",
    "    resize_dim=(1000, 1000),\n",
    ")\n",
    "\n",
    "for batch in dataset_iteratable:\n",
    "    #print(batch.shape)\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

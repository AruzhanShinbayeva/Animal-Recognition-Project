{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9720860,"sourceType":"datasetVersion","datasetId":5947458},{"sourceId":9730298,"sourceType":"datasetVersion","datasetId":5954512}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:14.982579Z","iopub.execute_input":"2024-11-19T15:44:14.982947Z","iopub.status.idle":"2024-11-19T15:44:23.505492Z","shell.execute_reply.started":"2024-11-19T15:44:14.982915Z","shell.execute_reply":"2024-11-19T15:44:23.504541Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\nRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.13.2)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"%matplotlib inline\n\nimport json\n\nfrom typing import Any, Tuple\n\n\n\nimport cv2\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nimport pandas as pd\n\nimport torch\n\nimport torch.nn as nn\n\nimport torch.optim as optim\n\nfrom cv2 import Mat\n\nfrom datasets import load_dataset\n\nfrom numpy import dtype, floating, integer, ndarray\n\nfrom torch.utils.data import DataLoader, Dataset, SubsetRandomSampler, Subset\n\nfrom tqdm import tqdm\n\nimport torch.nn.functional as F\n\n\n\nimport pandas as pd\n\n\n\nimport torchvision\n\nfrom torchvision import transforms\n\n\n\nplt.rcParams[\"figure.figsize\"] = (16, 10)  # (w, h)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:23.507445Z","iopub.execute_input":"2024-11-19T15:44:23.507762Z","iopub.status.idle":"2024-11-19T15:44:23.517792Z","shell.execute_reply.started":"2024-11-19T15:44:23.507733Z","shell.execute_reply":"2024-11-19T15:44:23.516875Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"with open(\"/kaggle/input/annotations/iwildcam2020_train_annotations.json\") as f:\n\n    data = json.load(f)\n\n\n\n\n\nannotations = pd.DataFrame.from_dict(data[\"annotations\"])\n\nimages_metadata = pd.DataFrame.from_dict(data[\"images\"])\n\ncategories = pd.DataFrame.from_dict(data[\"categories\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:23.518856Z","iopub.execute_input":"2024-11-19T15:44:23.519124Z","iopub.status.idle":"2024-11-19T15:44:25.419881Z","shell.execute_reply.started":"2024-11-19T15:44:23.519072Z","shell.execute_reply":"2024-11-19T15:44:25.419150Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# convert datetime type and split into day/night time\n\ndef split_day_night_time(\n\n    data: pd.DataFrame, day_start: str = \"06:00:00\", day_end: str = \"18:00:00\"\n\n) -> pd.DataFrame:\n\n    data = data.copy()\n\n    data[\"datetime\"] = pd.to_datetime(data[\"datetime\"])\n\n    data[\"is_day\"] = data[\"datetime\"].apply(\n\n        lambda x: True\n\n        if pd.Timestamp(day_start).time() <= x.time() < pd.Timestamp(day_end).time()\n\n        else False\n\n    )\n\n    return data\n\n\n\n\n\ndef preprocess_dark_images(\n\n    image: np.ndarray,\n\n) -> Mat | ndarray[Any, dtype[integer[Any] | floating[Any]]]:\n\n    img = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n\n    img_eq = img.copy()\n\n    img_eq[:, :, 0] = cv2.equalizeHist(img[:, :, 0])\n\n    final_img = cv2.cvtColor(img_eq, cv2.COLOR_LUV2RGB)\n\n    return final_img\n\n\n\n\n\ndef crop_black_lines(image: np.ndarray) -> np.ndarray:\n\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n    _, mask = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n\n\n\n    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    if contours:\n\n        x, y, w, h = cv2.boundingRect(contours[0])\n\n        cropped_image = image[y : y + h, x : x + w]\n\n        return cropped_image\n\n    else:\n\n        return image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:25.421981Z","iopub.execute_input":"2024-11-19T15:44:25.422275Z","iopub.status.idle":"2024-11-19T15:44:25.431565Z","shell.execute_reply.started":"2024-11-19T15:44:25.422246Z","shell.execute_reply":"2024-11-19T15:44:25.430372Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"from csv import Error\n\nfrom pathlib import Path\n\nfrom itertools import islice\n\nfrom PIL import Image, UnidentifiedImageError\n\n\n\n\n\nclass iWildCam2020Preprocessor:\n\n    def __init__(\n\n        self,\n\n        dataset: str,\n\n        metadata: pd.DataFrame,\n\n        annotations,\n\n        batch_size: int = 1,\n\n        resize_dim: Tuple[int, int] | None = None,\n\n        num_samples: int = 1000,\n\n        save_dir: str = \"./processed_images\",\n\n        overwrite: bool = False,\n\n    ):\n\n        self.metadata = metadata\n\n\n\n        self.dataset = dataset\n\n        self.resize_dim = resize_dim\n\n\n\n        self.num_samples = num_samples\n\n\n\n        self.save_dir = Path(save_dir)\n\n        self.save_dir.mkdir(parents=True, exist_ok=True)\n\n        self.overwrite = overwrite\n\n\n\n        self.batch_size = batch_size\n\n\n\n        self.annotations = annotations\n\n\n\n        unique_classes = self.annotations[\"category_id\"].unique()\n\n        category_to_index = {\n\n            category_id: index for index, category_id in enumerate(unique_classes)\n\n        }\n\n        self.annotations[\"mapped_category_id\"] = self.annotations[\"category_id\"].map(\n\n            category_to_index\n\n        )\n\n\n\n    @staticmethod\n\n    def is_valid(image: np.ndarray) -> bool:\n\n        if (\n\n            image.ndim not in [3, 4]\n\n            or image.shape[0] == 1\n\n            or image.shape[1] == 1\n\n            or image.shape[2] != 3\n\n        ):\n\n            print(f\"Skipping image with invalid shape: {image.shape}\")\n\n            return False, None\n\n\n\n        if image.ndim == 4:\n\n            image = np.squeeze(image, axis=-1)\n\n\n\n        if image.ndim == 3 and image.shape[2] == 3:\n\n            try:\n\n                img = Image.fromarray(image.astype(np.uint8), mode=\"RGB\")\n\n                img.verify()\n\n                img.load()\n\n                img = img.convert(\"RGB\")\n\n                return True, img\n\n            except (UnidentifiedImageError, IOError) as e:\n\n                print(f\"Error while processing RGB image: {e}\")\n\n                return False, None\n\n\n\n        return False, None\n\n\n\n    def preprocess_dataset(self):\n\n        existing_files = list(self.save_dir.glob(\"image_*.pt\"))\n\n        existing_files.sort(key=lambda x: int(x.stem.split(\"_\")[1]))\n\n\n\n        last_processed_index = (\n\n            int(existing_files[-1].stem.split(\"_\")[1]) if existing_files else 0\n\n        )\n\n        image_iterator = self.dataset.iter(batch_size=self.batch_size)\n\n        if last_processed_index != 0:\n\n            image_iterator = islice(\n\n                image_iterator, last_processed_index // self.batch_size\n\n            )\n\n\n\n        saved_samples = last_processed_index + 1 if last_processed_index != 0 else 0\n\n        idx = saved_samples\n\n        with tqdm(\n\n            total=self.num_samples,\n\n            initial=(last_processed_index + 1 if last_processed_index != 0 else 0),\n\n        ) as pbar:\n\n            while saved_samples < self.num_samples:\n\n                try:\n\n                    batch = next(image_iterator)\n\n                    for i, images in enumerate(batch[\"image\"]):\n\n                        save_path = self.save_dir / f\"image_{saved_samples}.pt\"\n\n\n\n                        if save_path.exists() and not self.overwrite:\n\n                            pbar.update(1)\n\n                            saved_samples += 1\n\n                            continue\n\n\n\n                        img_np = np.transpose(images.numpy())\n\n\n\n                        valid, img = self.is_valid(img_np)\n\n                        if not valid:\n\n                            pbar.update(0)\n\n                            continue\n\n\n\n                        img_np = np.array(img)\n\n\n\n                        is_day = self.metadata.iloc[idx + i][\"is_day\"]\n\n                        if not is_day:\n\n                            img_np = preprocess_dark_images(img_np)\n\n\n\n                        img_np = crop_black_lines(img_np)\n\n                        img_np = cv2.resize(\n\n                            img_np, self.resize_dim, interpolation=cv2.INTER_AREA\n\n                        )\n\n\n\n                        img_tensor = (\n\n                            torch.tensor(\n\n                                np.transpose(img_np, (2, 0, 1)), dtype=torch.float32\n\n                            )\n\n                            / 255.0\n\n                        )\n\n\n\n                        label = self.annotations.iloc[idx][\"mapped_category_id\"]\n\n                        data = {\n\n                            \"image\": img_tensor,\n\n                            \"label\": label,\n\n                        }\n\n\n\n                        if not save_path.exists() or self.overwrite:\n\n                            torch.save(data, save_path)\n\n\n\n                        saved_samples += 1\n\n                        pbar.update(1)\n\n\n\n                except Exception as e:\n                    pbar.update(0)\n\n                idx += self.batch_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:25.432667Z","iopub.execute_input":"2024-11-19T15:44:25.432926Z","iopub.status.idle":"2024-11-19T15:44:25.452135Z","shell.execute_reply.started":"2024-11-19T15:44:25.432900Z","shell.execute_reply":"2024-11-19T15:44:25.451271Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"class iWildCam2020Dataset(Dataset):\n\n    def __init__(\n\n        self,\n\n        annotations: pd.DataFrame,\n\n        transform: transforms.Compose | None = None,\n\n        save_dir: str = \"./data/processed_images\",\n\n    ):\n\n        self.save_dir = Path(save_dir)\n\n\n\n        self.transform = transform\n\n\n\n    def __len__(self):\n\n        return len(self.annotations)\n\n\n\n    def __getitem__(self, idx):\n\n        img_path = self.save_dir / f\"image_{idx}.pt\"\n\n        data = torch.load(img_path, weights_only=False)\n\n        \n\n        img_tensor = data[\"image\"]\n\n        label = data[\"label\"]\n\n\n\n        if self.transform:\n\n            img_tensor = self.transform(img_tensor)\n\n\n\n        return img_tensor, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:25.453301Z","iopub.execute_input":"2024-11-19T15:44:25.453579Z","iopub.status.idle":"2024-11-19T15:44:25.464453Z","shell.execute_reply.started":"2024-11-19T15:44:25.453554Z","shell.execute_reply":"2024-11-19T15:44:25.463600Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"import os\n\nfrom datetime import datetime\n\n\n\n\n\ndef get_unique_model_path(base_path):\n\n    if not os.path.exists(base_path):\n\n        return base_path\n\n\n\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n    unique_path = f\"{base_path}_{timestamp}.pt\"\n\n\n\n    while os.path.exists(unique_path):\n\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n        unique_path = f\"{base_path}_{timestamp}.pt\"\n\n\n\n    return unique_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:25.465579Z","iopub.execute_input":"2024-11-19T15:44:25.465828Z","iopub.status.idle":"2024-11-19T15:44:25.475249Z","shell.execute_reply.started":"2024-11-19T15:44:25.465804Z","shell.execute_reply":"2024-11-19T15:44:25.474449Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"from typing import Dict\n\nimport evaluate\n\n\n\n\n\ndef init_metrics() -> Dict[str, evaluate.Metric]:\n\n    return {\n\n        \"accuracy\": evaluate.load(\"accuracy\"),\n\n        \"precision\": evaluate.load(\"precision\", zero_division=0, average=\"macro\"),\n\n        \"recall\": evaluate.load(\"recall\", zero_division=0, average=\"macro\"),\n\n        \"f1\": evaluate.load(\"f1\", average=\"macro\"),\n\n    }\n\n\n\n\n\ndef compute_batch_metrics(metrics: Dict[str, evaluate.Metric]) -> Dict[str, float]:\n\n    computed_metrics = {}\n\n\n\n    computed_metrics[\"accuracy\"] = metrics[\"accuracy\"].compute()[\"accuracy\"]\n\n    computed_metrics[\"precision\"] = metrics[\"precision\"].compute(\n\n        zero_division=0, average=\"macro\"\n\n    )[\"precision\"]\n\n    computed_metrics[\"recall\"] = metrics[\"recall\"].compute(\n\n        zero_division=0, average=\"macro\"\n\n    )[\"recall\"]\n\n    computed_metrics[\"f1\"] = metrics[\"f1\"].compute(average=\"macro\")[\"f1\"]\n\n\n\n    return computed_metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:25.476100Z","iopub.execute_input":"2024-11-19T15:44:25.476386Z","iopub.status.idle":"2024-11-19T15:44:25.486415Z","shell.execute_reply.started":"2024-11-19T15:44:25.476360Z","shell.execute_reply":"2024-11-19T15:44:25.485579Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"from torch.amp import GradScaler, autocast\nimport random\n\n\ndef train_with_lora_and_hard_negatives(\n    model,\n    criterion,\n    optimizer,\n    train_loader,\n    val_loader,\n    batch_size,\n    num_samples,\n    device,\n    num_epochs=1,\n    ckpt_path=\"models/best.pt\",\n    use_mlflow=False,\n    use_wandb=False,\n    grad_clip_norm=None,\n    scheduler=None,\n    hard_negative_ratio=0.1,\n    hard_negative_update_freq=1,\n    use_amp=False,\n):\n    ckpt_path = ckpt_path #get_unique_model_path(ckpt_path)\n    best_accuracy = 0.0\n    metrics = init_metrics()\n\n    hard_negatives = []\n\n    if use_mlflow:\n        import mlflow\n\n        mlflow.start_run()\n        mlflow.log_params(\n            {\n                \"model\": model.__class__.__name__,\n                \"criterion\": criterion.__class__.__name__,\n                \"optimizer\": optimizer.__class__.__name__,\n                \"num_epochs\": num_epochs,\n                \"batch_size\": batch_size,\n                \"num_samples\": num_samples,\n                \"model_path\": ckpt_path,\n            }\n        )\n\n    scaler = GradScaler() if use_amp else None\n\n    # Training\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0.0\n        current_hard_negatives = []\n\n        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n            images, labels = images.to(device), labels.to(device)\n\n            if hard_negatives:\n                hard_neg_images, hard_neg_labels = sample_hard_negatives(hard_negatives, int(batch_size * hard_negative_ratio))\n                hard_neg_images, hard_neg_labels = hard_neg_images.to(device), hard_neg_labels.to(device)\n                images = torch.cat((images, hard_neg_images), dim=0)\n                labels = torch.cat((labels, hard_neg_labels), dim=0)\n\n            optimizer.zero_grad(set_to_none=True)\n            with autocast(device_type=\"cuda\", enabled=use_amp):\n                outputs = model(images)\n                ind_loss = torch.nn.functional.cross_entropy(outputs.logits, labels, reduction='none')\n                loss = ind_loss.mean()  # Mean loss for the batch\n\n            if use_amp and scaler:\n                scaler.scale(loss).backward()\n                if grad_clip_norm:\n                    scaler.unscale_(optimizer)\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n                scaler.step(optimizer)\n                scaler.update() \n            else:\n                loss.backward()\n                if grad_clip_norm:\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n                optimizer.step()\n\n\n            train_loss += loss.item()\n\n            _, preds = torch.max(outputs.logits, dim=1)\n            misclassified = preds != labels\n            hard_negative_losses = ind_loss[misclassified]\n            current_hard_negatives.extend(\n                [(images[i].cpu(), labels[i].cpu()) for i, _ in enumerate(hard_negative_losses)]\n            )\n\n            del images, labels, outputs, ind_loss\n            torch.cuda.empty_cache()\n\n        if scheduler:\n            scheduler.step()\n\n        # Update hard negatives\n        if epoch % hard_negative_update_freq == 0:\n            hard_negatives.extend(current_hard_negatives)\n            max_negatives = int(hard_negative_ratio * len(train_loader.dataset))\n            hard_negatives = hard_negatives[-max_negatives:]\n            torch.cuda.empty_cache()\n        \n\n        # Validation\n        val_loss = 0.0\n        model.eval()\n        computed_metrics = {}\n        with torch.no_grad():\n            for images, labels in tqdm(val_loader, desc=\"Validation\"):\n                images, labels = images.to(device), labels.to(device)\n                with autocast(device_type=\"cuda\", enabled=use_amp):\n                    outputs = model(images)\n                    loss = criterion(outputs.logits, labels)\n                val_loss += loss.item()\n\n                preds = outputs.logits.argmax(dim=1)\n                metrics[\"accuracy\"].add_batch(predictions=preds, references=labels)\n                metrics[\"precision\"].add_batch(predictions=preds, references=labels)\n                metrics[\"recall\"].add_batch(predictions=preds, references=labels)\n                metrics[\"f1\"].add_batch(predictions=preds, references=labels)\n\n                del images, labels, outputs, preds\n                torch.cuda.empty_cache()\n                \n            computed_metrics = compute_batch_metrics(metrics=metrics)\n\n        # Log and save\n        avg_train_loss = train_loss / len(train_loader)\n        avg_val_loss = val_loss / len(val_loader)\n        log_data = {\n            \"train_loss\": avg_train_loss,\n            \"val_loss\": avg_val_loss,\n            **computed_metrics,\n        }\n\n        if use_mlflow:\n            mlflow.log_metrics(log_data, step=epoch)\n        if use_wandb:\n            wandb.log(log_data)\n\n        print(\n            f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\"\n        )\n        print(f\"Metrics: {computed_metrics}\")\n\n        if computed_metrics[\"accuracy\"] > best_accuracy:\n            best_accuracy = computed_metrics[\"accuracy\"]\n            torch.save(model.state_dict(), ckpt_path)\n            if use_mlflow:\n                mlflow.pytorch.log_model(model, ckpt_path)\n\n    if use_mlflow:\n        mlflow.end_run()\n\n    torch.save(model.state_dict(), \"latest_model.pt\")\n\ndef sample_hard_negatives(hard_negatives, num_samples):\n    sampled_negatives = random.sample(hard_negatives, min(num_samples, len(hard_negatives)))\n    images, labels = zip(*sampled_negatives)\n    return torch.stack(images), torch.stack(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:25.487933Z","iopub.execute_input":"2024-11-19T15:44:25.488288Z","iopub.status.idle":"2024-11-19T15:44:25.507371Z","shell.execute_reply.started":"2024-11-19T15:44:25.488250Z","shell.execute_reply":"2024-11-19T15:44:25.506623Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"dataset = load_dataset(\n\n    \"anngrosha/iWildCam2020\", split=\"train\", streaming=True\n\n).with_format(\"torch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:25.509764Z","iopub.execute_input":"2024-11-19T15:44:25.509995Z","iopub.status.idle":"2024-11-19T15:44:27.515606Z","shell.execute_reply.started":"2024-11-19T15:44:25.509972Z","shell.execute_reply":"2024-11-19T15:44:27.514741Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/190 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b24ecaeb6e2d4f16a4b721d5c0e78606"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/52 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"263f2e58564e43f88962b5e489ad7f2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/190 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52b91957055849e68315906dee6cd9b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/52 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14fe7e0d5ceb4ed1a7472ad6dc6ac1c7"}},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"images_metadata = split_day_night_time(images_metadata)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:27.516780Z","iopub.execute_input":"2024-11-19T15:44:27.517154Z","iopub.status.idle":"2024-11-19T15:44:39.134143Z","shell.execute_reply.started":"2024-11-19T15:44:27.517115Z","shell.execute_reply":"2024-11-19T15:44:39.133379Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"batch_size = 100\n\nimg_size = 224\n\nresize_dim = (img_size, img_size)\n\nnum_classes = len(annotations[\"category_id\"].unique())\n\nprint(num_classes)\n\n\n\nnum_samples = 20_000\n\nval_ratio = 0.2\n\n\n\ntrain_size = int(num_samples * (1 - val_ratio))\n\nval_size = int(num_samples * val_ratio)\n\n\n\nnum_epochs = 70\n\n\n\nmean_std_samples = num_samples - int(num_samples * val_ratio)\n\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nsave_dir = \"./processed_images/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:39.135177Z","iopub.execute_input":"2024-11-19T15:44:39.135454Z","iopub.status.idle":"2024-11-19T15:44:39.144494Z","shell.execute_reply.started":"2024-11-19T15:44:39.135427Z","shell.execute_reply":"2024-11-19T15:44:39.143535Z"}},"outputs":[{"name":"stdout","text":"216\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"dataset_preprocessor = iWildCam2020Preprocessor(\n\n    dataset=dataset,\n\n    metadata=images_metadata,\n\n    resize_dim=resize_dim,\n\n    batch_size=100,\n\n    num_samples=num_samples,\n\n    save_dir=save_dir,\n\n    overwrite=False,\n\n    annotations=annotations,\n\n)\n\ndataset_preprocessor.preprocess_dataset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:39.145719Z","iopub.execute_input":"2024-11-19T15:44:39.146321Z","iopub.status.idle":"2024-11-19T15:44:39.633652Z","shell.execute_reply.started":"2024-11-19T15:44:39.146281Z","shell.execute_reply":"2024-11-19T15:44:39.632810Z"}},"outputs":[{"name":"stderr","text":"20076it [00:00, ?it/s]\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"def calculate_mean_std(\n\n    resize_dim=(224, 224),\n\n    num_samples=1000,\n\n    device=\"cpu\",\n\n    save_dir=\"./processed_images\",\n\n    save_files=True,\n\n):\n\n    total_pixels = 0\n\n    sum_mean = torch.zeros(3, dtype=torch.float32, device=device)\n\n    sum_std = torch.zeros(3, dtype=torch.float32, device=device)\n\n\n\n    image_files = list(Path(save_dir).glob(\"image_*.pt\"))\n\n    image_files.sort(key=lambda x: int(x.stem.split(\"_\")[1]))\n\n\n\n    image_files = image_files[:num_samples]\n\n\n\n    with tqdm(total=len(image_files)) as pbar:\n\n        for idx, image_file in enumerate(image_files):\n\n            img_tensor = torch.load(image_file, weights_only=False)[\"image\"].to(device)\n\n\n\n            img_tensor = torch.nn.functional.interpolate(\n\n                img_tensor.unsqueeze(0),\n\n                size=resize_dim,\n\n                mode=\"bilinear\",\n\n                align_corners=False,\n\n            ).squeeze(0)\n\n\n\n            img_tensor = img_tensor / 255.0  # Normalize to [0, 1]\n\n            sum_mean += img_tensor.mean(dim=(1, 2))\n\n            sum_std += img_tensor.std(dim=(1, 2))\n\n            total_pixels += img_tensor.numel()\n\n\n\n            pbar.update(1)\n\n\n\n    mean = sum_mean / total_pixels\n\n    std = sum_std / total_pixels\n\n\n\n    if save_files:\n\n        mean_file = Path(save_dir) / f\"mean_top_{num_samples}.pt\"\n\n        std_file = Path(save_dir) / f\"std_top_{num_samples}.pt\"\n\n        torch.save(mean, mean_file)\n\n        torch.save(std, std_file)\n\n\n\n    return mean, std\n\n\n\n\n\ndef get_mean_std_from_files(\n\n    save_dir=\"./processed_images\", num_samples=1000, device=\"cpu\"\n\n):\n\n    mean_file = Path(save_dir) / f\"mean_top_{num_samples}.pt\"\n\n    std_file = Path(save_dir) / f\"std_top_{num_samples}.pt\"\n\n\n\n    if mean_file.exists() and std_file.exists():\n\n        mean = torch.load(mean_file, weights_only=False)\n\n        std = torch.load(std_file, weights_only=False)\n\n        return mean, std\n\n    else:\n\n        return calculate_mean_std(\n\n            num_samples=num_samples, device=device, save_dir=save_dir, save_files=True\n\n        )\n\n\n\n\n\nmean, std = get_mean_std_from_files(save_dir, mean_std_samples, device=device)\n\nmean, std = mean.to(\"cpu\"), std.to(\"cpu\")\n\nmean, std","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:39.634736Z","iopub.execute_input":"2024-11-19T15:44:39.635273Z","iopub.status.idle":"2024-11-19T15:44:39.654379Z","shell.execute_reply.started":"2024-11-19T15:44:39.635232Z","shell.execute_reply":"2024-11-19T15:44:39.653433Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"(tensor([2.9336e-09, 2.8935e-09, 2.8360e-09]),\n tensor([1.3087e-09, 1.3413e-09, 1.4126e-09]))"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"transform = transforms.Compose(\n\n    [\n\n        transforms.RandomHorizontalFlip(p=0.5),\n\n        transforms.RandomResizedCrop(size=(224, 224)),\n\n        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n\n        transforms.RandomApply([transforms.GaussianBlur(3)], p=0.1),\n\n        transforms.Normalize(mean=mean, std=std),\n\n    ]\n\n)\n\n\n\ndataset = iWildCam2020Dataset(\n\n    annotations=annotations, save_dir=save_dir, transform=transform\n\n)\n\n\n\n\n\ntrain_idx = list(range(train_size))\n\nval_idx = list(range(train_size, num_samples))\n\n\n\ntrain_dataset = Subset(dataset, train_idx)\n\nval_dataset = Subset(dataset, val_idx)\n\n\n\ntrain_loader = DataLoader(\n\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=2\n)\n\nval_loader = DataLoader(\n\n    val_dataset, batch_size=batch_size, num_workers=1\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:39.655453Z","iopub.execute_input":"2024-11-19T15:44:39.655744Z","iopub.status.idle":"2024-11-19T15:44:39.664470Z","shell.execute_reply.started":"2024-11-19T15:44:39.655701Z","shell.execute_reply":"2024-11-19T15:44:39.663683Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"from transformers import AutoModelForImageClassification\n\n\n\nmodel = AutoModelForImageClassification.from_pretrained(\n\n    \"microsoft/swinv2-tiny-patch4-window16-256\"\n\n)\n\nmodel.classifier = nn.Linear(768, num_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:39.665450Z","iopub.execute_input":"2024-11-19T15:44:39.665677Z","iopub.status.idle":"2024-11-19T15:44:39.949526Z","shell.execute_reply.started":"2024-11-19T15:44:39.665654Z","shell.execute_reply":"2024-11-19T15:44:39.948811Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"import peft\n\nfrom peft import get_peft_model, LoraConfig\n\n\n\n\n\nlora_config = LoraConfig(\n\n    r=32,\n\n    lora_alpha=32,\n\n    lora_dropout=0.15,\n\n    target_modules=[\"query\", \"value\", \"key\"],\n\n    modules_to_save=[\"classifier\"],\n\n)\n\n\n\nmodel = get_peft_model(model, lora_config)\n\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:39.950539Z","iopub.execute_input":"2024-11-19T15:44:39.950869Z","iopub.status.idle":"2024-11-19T15:44:40.012959Z","shell.execute_reply.started":"2024-11-19T15:44:39.950831Z","shell.execute_reply":"2024-11-19T15:44:40.012139Z"}},"outputs":[{"name":"stdout","text":"trainable params: 590,040 || all params: 28,334,298 || trainable%: 2.0824\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"model = nn.DataParallel(model)\nmodel.to(device)\n\n\n\ncriterion = torch.nn.CrossEntropyLoss()\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.5)\n\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:40.013935Z","iopub.execute_input":"2024-11-19T15:44:40.014238Z","iopub.status.idle":"2024-11-19T15:44:40.091748Z","shell.execute_reply.started":"2024-11-19T15:44:40.014211Z","shell.execute_reply":"2024-11-19T15:44:40.091063Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"import wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:40.092546Z","iopub.execute_input":"2024-11-19T15:44:40.092845Z","iopub.status.idle":"2024-11-19T15:44:40.097255Z","shell.execute_reply.started":"2024-11-19T15:44:40.092820Z","shell.execute_reply":"2024-11-19T15:44:40.096385Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"wandb.login(key=\"093990e85b33005b3d11a8aa1f02c75283b67273\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:40.098402Z","iopub.execute_input":"2024-11-19T15:44:40.098688Z","iopub.status.idle":"2024-11-19T15:44:40.107962Z","shell.execute_reply.started":"2024-11-19T15:44:40.098664Z","shell.execute_reply":"2024-11-19T15:44:40.107176Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"wandb.init(project=\"animal-recognition\")\nwandb.config.update(\n    {\n        \"model\": str(model),\n        \"criterion\": str(criterion),\n        \"optimizer\": str(optimizer),\n        \"num_epochs\": num_epochs,\n        \"batch_size\": batch_size,\n        \"num_samples\": num_samples,\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:40.109173Z","iopub.execute_input":"2024-11-19T15:44:40.109681Z","iopub.status.idle":"2024-11-19T15:44:43.000741Z","shell.execute_reply.started":"2024-11-19T15:44:40.109647Z","shell.execute_reply":"2024-11-19T15:44:42.999791Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:a4gdk3i4) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.043 MB of 0.043 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd7d974800664df281dcd44ca52e3314"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">eager-surf-26</strong> at: <a href='https://wandb.ai/shinbayeva-shinbayeva/animal-recognition/runs/a4gdk3i4' target=\"_blank\">https://wandb.ai/shinbayeva-shinbayeva/animal-recognition/runs/a4gdk3i4</a><br/> View project at: <a href='https://wandb.ai/shinbayeva-shinbayeva/animal-recognition' target=\"_blank\">https://wandb.ai/shinbayeva-shinbayeva/animal-recognition</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241119_154147-a4gdk3i4/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:a4gdk3i4). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241119_154440-7abttu4n</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shinbayeva-shinbayeva/animal-recognition/runs/7abttu4n' target=\"_blank\">crimson-frost-27</a></strong> to <a href='https://wandb.ai/shinbayeva-shinbayeva/animal-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shinbayeva-shinbayeva/animal-recognition' target=\"_blank\">https://wandb.ai/shinbayeva-shinbayeva/animal-recognition</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shinbayeva-shinbayeva/animal-recognition/runs/7abttu4n' target=\"_blank\">https://wandb.ai/shinbayeva-shinbayeva/animal-recognition/runs/7abttu4n</a>"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"train_with_lora_and_hard_negatives(\n\n    model=model,\n\n    criterion=criterion,\n\n    optimizer=optimizer,\n\n    train_loader=train_loader,\n\n    val_loader=val_loader,\n\n    batch_size=batch_size,\n\n    num_samples=num_samples,\n\n    device=device,\n\n    num_epochs=num_epochs,\n\n    ckpt_path=\"best-lora.pt\",\n\n    grad_clip_norm=1.0,\n\n    scheduler=scheduler,\n\n    hard_negative_ratio=0.1,\n\n    hard_negative_update_freq=1,\n    use_amp=False,\n    use_wandb=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:44:43.001900Z","iopub.execute_input":"2024-11-19T15:44:43.002166Z","iopub.status.idle":"2024-11-19T17:41:37.392644Z","shell.execute_reply.started":"2024-11-19T15:44:43.002140Z","shell.execute_reply":"2024-11-19T17:41:37.389958Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 1/70: 100%|██████████| 160/160 [04:16<00:00,  1.57s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 1/70: 100%|██████████| 160/160 [04:16<00:00,  1.60s/it]\nValidation: 100%|██████████| 40/40 [01:03<00:00,  1.59s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/70], Train Loss: 2.6783, Val Loss: 4.5460\nMetrics: {'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 2/70: 100%|██████████| 160/160 [04:44<00:00,  1.71s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 2/70: 100%|██████████| 160/160 [04:45<00:00,  1.78s/it]\nValidation: 100%|██████████| 40/40 [01:01<00:00,  1.53s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/70], Train Loss: 2.6158, Val Loss: 4.5778\nMetrics: {'accuracy': 0.35, 'precision': 0.02692307692307692, 'recall': 0.07692307692307693, 'f1': 0.039886039886039885}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 3/70: 100%|██████████| 160/160 [04:45<00:00,  1.74s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 3/70: 100%|██████████| 160/160 [04:46<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:03<00:00,  1.59s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/70], Train Loss: 2.6061, Val Loss: 4.4642\nMetrics: {'accuracy': 0.35, 'precision': 0.02692307692307692, 'recall': 0.07692307692307693, 'f1': 0.039886039886039885}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 4/70: 100%|██████████| 160/160 [04:44<00:00,  1.74s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 4/70: 100%|██████████| 160/160 [04:45<00:00,  1.78s/it]\nValidation: 100%|██████████| 40/40 [01:04<00:00,  1.62s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/70], Train Loss: 2.5831, Val Loss: 4.3929\nMetrics: {'accuracy': 0.308, 'precision': 0.02686202686202686, 'recall': 0.06285714285714286, 'f1': 0.03763900769888794}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 5/70: 100%|██████████| 160/160 [04:45<00:00,  1.73s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 5/70: 100%|██████████| 160/160 [04:46<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:06<00:00,  1.67s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/70], Train Loss: 2.5601, Val Loss: 4.6342\nMetrics: {'accuracy': 0.33825, 'precision': 0.02518052557135413, 'recall': 0.06903061224489795, 'f1': 0.03690067092128948}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 6/70: 100%|██████████| 160/160 [04:45<00:00,  1.73s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 6/70: 100%|██████████| 160/160 [04:46<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:03<00:00,  1.60s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/70], Train Loss: 2.5317, Val Loss: 4.5372\nMetrics: {'accuracy': 0.311, 'precision': 0.027024678484532497, 'recall': 0.06346938775510204, 'f1': 0.037908337396392}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 7/70: 100%|██████████| 160/160 [04:44<00:00,  1.74s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 7/70: 100%|██████████| 160/160 [04:45<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:04<00:00,  1.60s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/70], Train Loss: 2.5127, Val Loss: 4.5437\nMetrics: {'accuracy': 0.30925, 'precision': 0.02695458903512595, 'recall': 0.06311224489795918, 'f1': 0.037775606180907584}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 8/70: 100%|██████████| 160/160 [04:43<00:00,  1.72s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 8/70: 100%|██████████| 160/160 [04:44<00:00,  1.78s/it]\nValidation: 100%|██████████| 40/40 [01:03<00:00,  1.59s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/70], Train Loss: 2.5113, Val Loss: 4.6280\nMetrics: {'accuracy': 0.30125, 'precision': 0.027007037518490293, 'recall': 0.061479591836734696, 'f1': 0.037528418823382856}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 9/70: 100%|██████████| 160/160 [04:45<00:00,  1.73s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 9/70: 100%|██████████| 160/160 [04:46<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:04<00:00,  1.62s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/70], Train Loss: 2.5099, Val Loss: 4.5430\nMetrics: {'accuracy': 0.313, 'precision': 0.026976944624003445, 'recall': 0.06387755102040817, 'f1': 0.03793364641720952}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 10/70: 100%|██████████| 160/160 [04:45<00:00,  1.72s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 10/70: 100%|██████████| 160/160 [04:46<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:03<00:00,  1.60s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/70], Train Loss: 2.5135, Val Loss: 4.5820\nMetrics: {'accuracy': 0.30675, 'precision': 0.02709207330536542, 'recall': 0.06260204081632653, 'f1': 0.03781784558483587}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 11/70: 100%|██████████| 160/160 [04:46<00:00,  1.75s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 11/70: 100%|██████████| 160/160 [04:47<00:00,  1.80s/it]\nValidation: 100%|██████████| 40/40 [01:06<00:00,  1.67s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [11/70], Train Loss: 2.5059, Val Loss: 4.6039\nMetrics: {'accuracy': 0.3025, 'precision': 0.027068140127958478, 'recall': 0.061734693877551025, 'f1': 0.03763491026717676}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 12/70: 100%|██████████| 160/160 [04:45<00:00,  1.72s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 12/70: 100%|██████████| 160/160 [04:46<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:02<00:00,  1.56s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [12/70], Train Loss: 2.5010, Val Loss: 4.6139\nMetrics: {'accuracy': 0.3055, 'precision': 0.02713264354545051, 'recall': 0.06234693877551021, 'f1': 0.03781057582227173}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 13/70: 100%|██████████| 160/160 [04:44<00:00,  1.73s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 13/70: 100%|██████████| 160/160 [04:45<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:00<00:00,  1.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [13/70], Train Loss: 2.5018, Val Loss: 4.6149\nMetrics: {'accuracy': 0.30625, 'precision': 0.027140198511166252, 'recall': 0.0625, 'f1': 0.03784602076124567}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 14/70: 100%|██████████| 160/160 [04:45<00:00,  1.73s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 14/70: 100%|██████████| 160/160 [04:46<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:01<00:00,  1.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [14/70], Train Loss: 2.5011, Val Loss: 4.6335\nMetrics: {'accuracy': 0.3045, 'precision': 0.027153558052434457, 'recall': 0.062142857142857146, 'f1': 0.03779322328410078}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 15/70: 100%|██████████| 160/160 [04:45<00:00,  1.74s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 15/70: 100%|██████████| 160/160 [04:45<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:01<00:00,  1.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [15/70], Train Loss: 2.5003, Val Loss: 4.6361\nMetrics: {'accuracy': 0.30525, 'precision': 0.027262983968204348, 'recall': 0.062295918367346936, 'f1': 0.037927499767030096}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 16/70: 100%|██████████| 160/160 [04:44<00:00,  1.75s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 16/70: 100%|██████████| 160/160 [04:45<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:02<00:00,  1.55s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [16/70], Train Loss: 2.5023, Val Loss: 4.6374\nMetrics: {'accuracy': 0.30475, 'precision': 0.02713350843609491, 'recall': 0.062193877551020404, 'f1': 0.03778321916746737}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 17/70: 100%|██████████| 160/160 [04:45<00:00,  1.73s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 17/70: 100%|██████████| 160/160 [04:46<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [17/70], Train Loss: 2.5055, Val Loss: 4.6383\nMetrics: {'accuracy': 0.305, 'precision': 0.027147307521139297, 'recall': 0.06224489795918368, 'f1': 0.037806011775643016}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 18/70: 100%|██████████| 160/160 [04:45<00:00,  1.72s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 18/70: 100%|██████████| 160/160 [04:46<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:02<00:00,  1.57s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [18/70], Train Loss: 2.5024, Val Loss: 4.6434\nMetrics: {'accuracy': 0.304, 'precision': 0.027134377649841567, 'recall': 0.062040816326530614, 'f1': 0.03775576737976217}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 19/70: 100%|██████████| 160/160 [04:45<00:00,  1.74s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 19/70: 100%|██████████| 160/160 [04:46<00:00,  1.79s/it]\nValidation: 100%|██████████| 40/40 [01:01<00:00,  1.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [19/70], Train Loss: 2.5002, Val Loss: 4.6471\nMetrics: {'accuracy': 0.3035, 'precision': 0.027115161261502724, 'recall': 0.06193877551020408, 'f1': 0.03771826259864537}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 20/70: 100%|██████████| 160/160 [04:44<00:00,  1.73s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 20/70: 100%|██████████| 160/160 [04:45<00:00,  1.78s/it]\nValidation: 100%|██████████| 40/40 [01:02<00:00,  1.57s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [20/70], Train Loss: 2.5019, Val Loss: 4.6476\nMetrics: {'accuracy': 0.30475, 'precision': 0.02715042986324558, 'recall': 0.062193877551020404, 'f1': 0.03779962169369593}\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/70:   0%|          | 0/160 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 21/70:  16%|█▋        | 26/160 [00:47<03:53,  1.74s/it]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 21/70:  16%|█▋        | 26/160 [00:48<04:10,  1.87s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_with_lora_and_hard_negatives\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest-lora.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_clip_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhard_negative_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhard_negative_update_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[39], line 65\u001b[0m, in \u001b[0;36mtrain_with_lora_and_hard_negatives\u001b[0;34m(model, criterion, optimizer, train_loader, val_loader, batch_size, num_samples, device, num_epochs, ckpt_path, use_mlflow, use_wandb, grad_clip_norm, scheduler, hard_negative_ratio, hard_negative_update_freq, use_amp)\u001b[0m\n\u001b[1;32m     63\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, enabled\u001b[38;5;241m=\u001b[39muse_amp):\n\u001b[0;32m---> 65\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     ind_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(outputs\u001b[38;5;241m.\u001b[39mlogits, labels, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     67\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ind_loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# Mean loss for the batch\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:186\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    185\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 186\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:201\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:100\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     98\u001b[0m         thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m thread \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m--> 100\u001b[0m         \u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     _worker(\u001b[38;5;241m0\u001b[39m, modules[\u001b[38;5;241m0\u001b[39m], inputs[\u001b[38;5;241m0\u001b[39m], kwargs_tup[\u001b[38;5;241m0\u001b[39m], devices[\u001b[38;5;241m0\u001b[39m], streams[\u001b[38;5;241m0\u001b[39m])\n","File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":52}]}